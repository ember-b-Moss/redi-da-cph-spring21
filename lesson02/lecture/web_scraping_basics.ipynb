{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inspect the website's source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Refresher\n",
    "This part is based on chapter 11 of *Automate the Boring Stuff with Python* by Al Sweigart\n",
    "\n",
    "HTML files are plain text files containing *tags*, which are words enclosed in angle brackets. Tags tell the browser how to format the web page. A starting tag and closing tag can enclose some text to form an element. The text (or inner HTML) is the content between the starting and closing tags.\n",
    "\n",
    "There are many different tags in HTML. Some of these tags have extra properties in the form of attributes within the angle brackets. For example, the `<a>` tag encloses text that should be a link.\n",
    "\n",
    "Some elements have an `id` attribute that is used to uniquely identify the element in the page. You will often instruct your programs to seek out an element by its id attribute, so figuring out an element’s id attribute using the browser’s developer tools is a common task in writing web scraping programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View a page's HTML source\n",
    "\n",
    "In Firefox:\n",
    "To view a page's sources right click on it and choose **View page source** which opens a new tab with the HTML sources.\n",
    "<img src=\"resources/img/view_page_source.png\" width=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fetching data\n",
    "Use Python's `requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/benesom/redi-da-cph-spring21'\n",
    "r = requests.get(url)\n",
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parse data and extract from it with BeautifulSoup\n",
    "\n",
    "BeautifulSoup is a module for parsing and extracting information from HTML sources. The module’s name is bs4. In case it is not already installed on your machine:\n",
    "- install it with \n",
    "```bash \n",
    "pip install beautifulsoup4\n",
    "\n",
    "While beautifulsoup4 is the name used for installation, to import BeautifulSoup in your notebook you have to use `import bs4`.\n",
    "\n",
    "Documentation: https://www.crummy.com/software/BeautifulSoup/\n",
    "\n",
    "_\"Beautiful Soup parses anything you give it, and does the tree traversal stuff for you. You can tell it \"Find all the links\", or \"Find all the links of class externalLink\", or \"Find all the links whose urls match \"foo.com\", or \"Find the table heading that's got bold text, then give me that text.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Creating a BeautifulSoup Object from our local HTML File\n",
    "\n",
    "- The `bs4.BeautifulSoup()` function needs to be called with a string containing the HTML file it will parse and returns a `BeautifulSoup` object.\n",
    "\n",
    "You can load a local HTML file and pass a file object to `bs4.BeautifulSoup()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "with open('resources/example.html') as f:\n",
    "    example_html = f.read()\n",
    "    \n",
    "soup = bs4.BeautifulSoup(example_html)\n",
    "print(type(soup))\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B Creating a BeautifulSoup object from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/benesom/redi-da-cph-spring21'\n",
    "\n",
    "r = requests.get(url)\n",
    "r.raise_for_status()\n",
    "soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an Element with the `select()` Method\n",
    "\n",
    "You can retrieve HTML elements from a `BeautifulSoup` object by calling the `select()` method and passing a string of a CSS selector for the element you are looking for. Selectors are like regular expressions: They specify a pattern to look for, in this case, in HTML pages instead of general text strings.\n",
    "\n",
    "Common CSS selector patterns include:\n",
    "\n",
    "  * `soup.select('div')` ... selects all elements named `<div>`\n",
    "  * `soup.select('#lecturer')`  ... selects the element with an id attribute of author\n",
    "  * `soup.select('.notice')` ... selects all elements that use a CSS class attribute named notice\n",
    "  * `soup.select('div span')` ... selects all elements named `<span>` that are within an element named `<div>`\n",
    "  * `soup.select('div > span')` ... selects all elements named `<span>` that are directly within an element named `<div>`, with no other element in between\n",
    "  * `soup.select('input[name]')` ... selects all elements named `<input>` that have a name attribute with any value\n",
    "  * `soup.select('input[type=\"button\"]')` ... selects all elements named `<input>` that have an attribute named type with value button\n",
    "  \n",
    "See more in the documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/example.html') as f:\n",
    "    example_html = f.read()\n",
    "\n",
    "soup = bs4.BeautifulSoup(example_html, 'html.parser')\n",
    "\n",
    "elems = soup.select('body')\n",
    "\n",
    "#print(soup.prettify())\n",
    "print('1: return type of select()',type(elems))\n",
    "print('2: length of the returned list',len(elems))\n",
    "print('3: type of elements in the list',type(elems[0]))\n",
    "print('4: get text from the element',elems[0].getText()[:40])\n",
    "print('5: string representation of an element: ',str(elems[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting a link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_elems = soup.select('a')\n",
    "a_elems[0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the difference between the `select` and the `find`/`find_all` functions?\n",
    "\n",
    "You are not the first ones wondering about this... See:\n",
    "https://stackoverflow.com/questions/38028384/beautifulsoup-is-there-a-difference-between-find-and-select-python-3-x#38033910"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Notes\n",
    "\n",
    "**OBS** Many web pages are not built to support high traffic or they explicitely discourage automatic access. Keep this in mind when writing your scraping tool.\n",
    "\n",
    "If you are interested in more web scraping and application of crawlers have a look at the `scrapy` module (https://scrapy.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "sleep(3) # script doesn't continue for 3 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Scraping Events from a Page\n",
    "\n",
    "Let's scrape some apartment prices from boliga.dk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "url = \"https://www.boliga.dk/salg/resultater?page=1&sort=date-d&salesDateMax=2021&street=&municipality=101\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.raise_for_status\n",
    "soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.find_all('tr', attrs={'class': 'table-row'})\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for row in rows:\n",
    "    bolig_dict = {}\n",
    "    cols = row.find_all('td')\n",
    "    bolig_dict['address'] = cols[0].text\n",
    "    bolig_dict['price'] = cols[1].text\n",
    "    bolig_dict['size'] = cols[6].text\n",
    "    bolig_dict['rooms'] = cols[5].text\n",
    "    bolig_dict['built_year'] = cols[7].text\n",
    "    result_list.append(bolig_dict)\n",
    "\n",
    "result_list[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(result_list)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
